# -*- coding: utf-8 -*-
"""AOS C111 Final Project

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wpGlpZpiO5V3PaYge65WRyUqORV-5_Vn
"""

!pip install requests

!pip install torch torchvision matplotlib opencv-python

!pip install roboflow

!pip install tqdm

!pip install roboflow

!pip install grad-cam

import os
import torch
import torch.nn as nn
from torchvision import datasets, models, transforms
from torch.utils.data import DataLoader
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from roboflow import Roboflow

rf = Roboflow(api_key="Z1YZnjQqF04occAwlv4A")
project = rf.workspace("nab").project("health_coral-qprbe")
version = project.version(1)
dataset = version.download("folder")

dataset_path = "./health_coral-1"
print(os.listdir(dataset_path))

# Define transformations for training and validation datasets
transform_train = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(),
    transforms.ColorJitter(brightness=0.2, contrast=0.2),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

transform_val = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

# Load datasets
train_dataset = datasets.ImageFolder(os.path.join(dataset_path, "train"), transform=transform_train)
val_dataset = datasets.ImageFolder(os.path.join(dataset_path, "valid"), transform=transform_val)

# Create DataLoaders
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)

# Print class names
class_names = train_dataset.classes
print("Classes:", class_names)

# Visualize class distribution
import matplotlib.pyplot as plt
from collections import Counter

class_counts = Counter([label for _, label in train_dataset])
plt.bar(class_names, [class_counts[i] for i in range(len(class_names))])
plt.xlabel('Coral Health Categories')
plt.ylabel('Frequency')
plt.title('Training Class Distribution')
plt.show()

import random

def show_images(dataset, num_images=9):
    """
    Display a grid of random images from the dataset.
    Args:
        dataset: A PyTorch ImageFolder dataset.
        num_images: Number of images to display.
    """
    # Ensure we don't sample more images than available
    num_images = min(num_images, len(dataset))

    # Randomly sample indices
    random_indices = random.sample(range(len(dataset)), num_images)

    fig, axes = plt.subplots(3, 3, figsize=(10, 10))  # Adjust grid size if needed
    for i, idx in enumerate(random_indices):
        img, label = dataset[idx]  # Fetch image and label
        # Convert to HWC format for matplotlib and denormalize
        img = img.permute(1, 2, 0).numpy()
        img = np.clip(img * [0.229, 0.224, 0.225] + [0.485, 0.456, 0.406], 0, 1)
        ax = axes[i // 3, i % 3]
        ax.imshow(img)
        ax.set_title(f"Class: {dataset.classes[label]}")
        ax.axis("off")

    plt.tight_layout()
    plt.show()

show_images(train_dataset)

import torch
import torch.nn as nn
from torchvision.models import resnet50

# Device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Load pre-trained ResNet50
model = resnet50(pretrained=True)

# Replace the final fc layer to match the number of classes
num_classes = len(class_names)
model.fc = nn.Linear(model.fc.in_features, num_classes)

# Move model to device
model = model.to(device)

from tqdm import tqdm
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim.lr_scheduler import StepLR

# Loss function
criterion = nn.CrossEntropyLoss()

# Optimizer and scheduler
optimizer = optim.Adam(model.parameters(), lr=0.001)
scheduler = StepLR(optimizer, step_size=5, gamma=0.1)

# Training loop
train_losses, val_losses, val_accuracies = [], [], []

# Class names (replace with your actual class names)
class_names = ['Healthy', 'Damaged', 'Bleached']  # Example class names

# Number of epochs
num_epochs = 10

for epoch in range(num_epochs):  # Training for 10 epochs
    print(f"\nEpoch {epoch+1}/{num_epochs}")

    # Training phase
    model.train()
    running_loss = 0.0
    train_loader_progress = tqdm(train_loader, desc=f"Training", leave=True)

    for batch_idx, (inputs, labels) in enumerate(train_loader_progress):
        inputs, labels = inputs.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()

        # Update progress bar with current loss
        train_loader_progress.set_postfix({"Batch Loss": loss.item()})

    train_loader_progress.close()
    train_losses.append(running_loss / len(train_loader))

    # Validation phase
    model.eval()
    val_loss, correct, total = 0.0, 0, 0
    all_preds, all_labels = [], []
    val_loader_progress = tqdm(val_loader, desc=f"Validation", leave=True)

    with torch.no_grad():
        for batch_idx, (inputs, labels) in enumerate(val_loader_progress):
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            val_loss += loss.item()
            _, preds = torch.max(outputs, 1)
            correct += (preds == labels).sum().item()
            total += labels.size(0)

            # Collect predictions and labels
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

            # Update progress bar with current batch accuracy
            val_loader_progress.set_postfix({"Batch Accuracy": (preds == labels).float().mean().item()})

    val_loader_progress.close()
    val_losses.append(val_loss / len(val_loader))
    val_accuracies.append(correct / total)
    scheduler.step()

    # Print summary for the epoch
    print(f"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_losses[-1]:.4f}, "
          f"Val Loss: {val_losses[-1]:.4f}, Val Accuracy: {val_accuracies[-1]:.4f}")

# Final results summary
print("\nTraining Completed!")
print("Final Training Loss:", train_losses[-1])
print("Final Validation Loss:", val_losses[-1])
print("Final Validation Accuracy:", val_accuracies[-1])

# Classification Report
print("\nClassification Report:")
print(classification_report(all_labels, all_preds, target_names=class_names))

# Confusion Matrix
cm = confusion_matrix(all_labels, all_preds)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=class_names, yticklabels=class_names)
plt.title(f"Confusion Matrix - Epoch {epoch+1}")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.show()

# Plot Training and Validation Loss
plt.figure(figsize=(10, 5))
plt.plot(train_losses, label="Training Loss")
plt.plot(val_losses, label="Validation Loss")
plt.title("Training and Validation Loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend()
plt.show()

"""# Improving the model"""

from albumentations import Compose, HorizontalFlip, RandomBrightnessContrast, GaussianBlur, CLAHE
from albumentations.pytorch import ToTensorV2

# Replace transform_train with Albumentations pipeline
transform_train = Compose([
    HorizontalFlip(p=0.5),
    RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),
    GaussianBlur(blur_limit=(3, 7), p=0.3),
    CLAHE(clip_limit=2.0, p=0.3),
    ToTensorV2()
])

train_dataset = datasets.ImageFolder(os.path.join(dataset_path, "train"), transform=transform_train)

# Add Dropout to the fully connected layer
model.fc = nn.Sequential(
    nn.Dropout(0.5),  # Dropout layer to prevent overfitting
    nn.Linear(model.fc.in_features, num_classes)
)

# Use AdamW optimizer with weight decay
optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)

# Replace scheduler with Cosine Annealing
scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=1e-6)

# Training loop
train_losses, val_losses, val_accuracies = [], [], []

# Class names (replace with your actual class names)
class_names = ['Healthy', 'Damaged', 'Bleached']  # Example class names

# Number of epochs
num_epochs = 10

for epoch in range(num_epochs):  # Training for 10 epochs
    print(f"\nEpoch {epoch+1}/{num_epochs}")

    # Training phase
    model.train()
    running_loss = 0.0
    train_loader_progress = tqdm(train_loader, desc=f"Training", leave=True)

    for batch_idx, (inputs, labels) in enumerate(train_loader_progress):
        inputs, labels = inputs.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()

        # Update progress bar with current loss
        train_loader_progress.set_postfix({"Batch Loss": loss.item()})

    train_loader_progress.close()
    train_losses.append(running_loss / len(train_loader))

    # Validation phase
    model.eval()
    val_loss, correct, total = 0.0, 0, 0
    all_preds, all_labels = [], []
    val_loader_progress = tqdm(val_loader, desc=f"Validation", leave=True)

    with torch.no_grad():
        for batch_idx, (inputs, labels) in enumerate(val_loader_progress):
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            val_loss += loss.item()
            _, preds = torch.max(outputs, 1)
            correct += (preds == labels).sum().item()
            total += labels.size(0)

            # Collect predictions and labels
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

            # Update progress bar with current batch accuracy
            val_loader_progress.set_postfix({"Batch Accuracy": (preds == labels).float().mean().item()})

    val_loader_progress.close()
    val_losses.append(val_loss / len(val_loader))
    val_accuracies.append(correct / total)
    scheduler.step()

    # Print summary for the epoch
    print(f"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_losses[-1]:.4f}, "
          f"Val Loss: {val_losses[-1]:.4f}, Val Accuracy: {val_accuracies[-1]:.4f}")

# Final results summary
print("\nTraining Completed!")
print("Final Training Loss:", train_losses[-1])
print("Final Validation Loss:", val_losses[-1])
print("Final Validation Accuracy:", val_accuracies[-1])

# Classification Report
print("\nClassification Report:")
print(classification_report(all_labels, all_preds, target_names=class_names))

# Confusion Matrix
cm = confusion_matrix(all_labels, all_preds)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=class_names, yticklabels=class_names)
plt.title(f"Confusion Matrix - Epoch {epoch+1}")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.show()

# Plot Training and Validation Loss
plt.figure(figsize=(10, 5))
plt.plot(train_losses, label="Training Loss")
plt.plot(val_losses, label="Validation Loss")
plt.title("Training and Validation Loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend()
plt.show()

"""# Grad-CAM Implementation"""

!pip install grad-cam

from pytorch_grad_cam import GradCAM
from pytorch_grad_cam.utils.image import show_cam_on_image
import matplotlib.pyplot as plt

# Initialize Grad-CAM with the desired target layer
target_layer = model.layer4[-1]  # Last convolutional block of ResNet50
cam = GradCAM(model=model, target_layers=[target_layer], use_cuda=torch.cuda.is_available())

from torchvision.transforms.functional import to_pil_image

def visualize_gradcam(input_tensor, label, model, target_layer, class_names):
    """
    Generate and visualize Grad-CAM heatmap for a given input.

    Args:
        input_tensor: Single input image tensor (1 x C x H x W).
        label: Ground truth label of the input image.
        model: Trained PyTorch model.
        target_layer: Layer to target for Grad-CAM.
        class_names: List of class names.

    Returns:
        None
    """
    # Initialize Grad-CAM
    cam = GradCAM(model=model, target_layers=[target_layer], use_cuda=torch.cuda.is_available())

    # Generate Grad-CAM heatmap
    grayscale_cam = cam(input_tensor=input_tensor)[0]

    # Convert tensor to image
    image = input_tensor[0].permute(1, 2, 0).cpu().numpy()  # Convert to HWC format
    image = (image - image.min()) / (image.max() - image.min())  # Normalize to [0, 1]

    # Overlay Grad-CAM on the image
    visualization = show_cam_on_image(image, grayscale_cam, use_rgb=True)

    # Display the result
    plt.figure(figsize=(6, 6))
    plt.imshow(visualization)
    plt.title(f"Grad-CAM Visualization\nLabel: {class_names[label]}")
    plt.axis("off")
    plt.show()

model.eval()
misclassified = []

with torch.no_grad():
    for inputs, labels in val_loader:
        inputs, labels = inputs.to(device), labels.to(device)
        outputs = model(inputs)
        _, preds = torch.max(outputs, 1)

        # Collect misclassified examples
        for i in range(len(preds)):
            if preds[i] != labels[i]:  # Check for misclassification
                misclassified.append((inputs[i], labels[i], preds[i]))

print(f"Total misclassified examples: {len(misclassified)}")

# Visualize Grad-CAM for the first 5 misclassified examples
for img, true_label, pred_label in misclassified[:5]:
    input_tensor = img.unsqueeze(0)  # Add batch dimension
    print(f"True Label: {class_names[true_label.item()]}, Predicted: {class_names[pred_label.item()]}")
    visualize_gradcam(input_tensor, true_label.item(), model, target_layer, class_names)

correctly_classified = []

with torch.no_grad():
    for inputs, labels in val_loader:
        inputs, labels = inputs.to(device), labels.to(device)
        outputs = model(inputs)
        _, preds = torch.max(outputs, 1)

        # Collect correctly classified examples
        for i in range(len(preds)):
            if preds[i] == labels[i]:  # Check for correct classification
                correctly_classified.append((inputs[i], labels[i]))

# Visualize Grad-CAM for the first 5 correctly classified examples
print(f"Total correctly classified examples: {len(correctly_classified)}")

for img, label in correctly_classified[:5]:
    input_tensor = img.unsqueeze(0)  # Add batch dimension
    visualize_gradcam(input_tensor, label.item(), model, target_layer, class_names)