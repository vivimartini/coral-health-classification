# -*- coding: utf-8 -*-
"""AOS C111 Final Project

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wpGlpZpiO5V3PaYge65WRyUqORV-5_Vn
"""

!pip install requests

!pip install torch torchvision matplotlib opencv-python

!pip install roboflow

!pip install tqdm

!pip install roboflow

!pip install grad-cam

import os
import torch
import torch.nn as nn
from torchvision import datasets, models, transforms
from torch.utils.data import DataLoader
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from roboflow import Roboflow

rf = Roboflow(api_key="Z1YZnjQqF04occAwlv4A")
project = rf.workspace("nab").project("health_coral-qprbe")
version = project.version(1)
dataset = version.download("folder")

dataset_path = "./health_coral-1"
print(os.listdir(dataset_path))

# Define transformations for training and validation datasets
transform_train = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(),
    transforms.ColorJitter(brightness=0.2, contrast=0.2),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

transform_val = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

# Load datasets
train_dataset = datasets.ImageFolder(os.path.join(dataset_path, "train"), transform=transform_train)
val_dataset = datasets.ImageFolder(os.path.join(dataset_path, "valid"), transform=transform_val)

# Create DataLoaders
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)

# Print class names
class_names = train_dataset.classes
print("Classes:", class_names)

# Visualize class distribution
import matplotlib.pyplot as plt
from collections import Counter

class_counts = Counter([label for _, label in train_dataset])
plt.bar(class_names, [class_counts[i] for i in range(len(class_names))])
plt.xlabel('Coral Health Categories')
plt.ylabel('Frequency')
plt.title('Training Class Distribution')
plt.show()

import random

def show_images(dataset, num_images=9):
    """
    Display a grid of random images from the dataset.
    Args:
        dataset: A PyTorch ImageFolder dataset.
        num_images: Number of images to display.
    """
    # Ensure we don't sample more images than available
    num_images = min(num_images, len(dataset))

    # Randomly sample indices
    random_indices = random.sample(range(len(dataset)), num_images)

    fig, axes = plt.subplots(3, 3, figsize=(10, 10))  # Adjust grid size if needed
    for i, idx in enumerate(random_indices):
        img, label = dataset[idx]  # Fetch image and label
        # Convert to HWC format for matplotlib and denormalize
        img = img.permute(1, 2, 0).numpy()
        img = np.clip(img * [0.229, 0.224, 0.225] + [0.485, 0.456, 0.406], 0, 1)
        ax = axes[i // 3, i % 3]
        ax.imshow(img)
        ax.set_title(f"Class: {dataset.classes[label]}")
        ax.axis("off")

    plt.tight_layout()
    plt.show()

show_images(train_dataset)

import torch
import torch.nn as nn
from torchvision.models import resnet50

# Device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Load pre-trained ResNet50
model = resnet50(pretrained=True)

# Replace the final fc layer to match the number of classes
num_classes = len(class_names)
model.fc = nn.Linear(model.fc.in_features, num_classes)

# Move model to device
model = model.to(device)

from tqdm import tqdm
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim.lr_scheduler import StepLR

# Loss function
criterion = nn.CrossEntropyLoss()

# Optimizer and scheduler
optimizer = optim.Adam(model.parameters(), lr=0.001)
scheduler = StepLR(optimizer, step_size=5, gamma=0.1)

# Training loop
train_losses, val_losses, val_accuracies = [], [], []

class_names = ['bleached', 'healthy', 'partially']

# Number of epochs
num_epochs = 10

for epoch in range(num_epochs):  # Training for 10 epochs
    print(f"\nEpoch {epoch+1}/{num_epochs}")

    # Training phase
    model.train()
    running_loss = 0.0
    train_loader_progress = tqdm(train_loader, desc=f"Training", leave=True)

    for batch_idx, (inputs, labels) in enumerate(train_loader_progress):
        inputs, labels = inputs.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()

        # Update progress bar with current loss
        train_loader_progress.set_postfix({"Batch Loss": loss.item()})

    train_loader_progress.close()
    train_losses.append(running_loss / len(train_loader))

    # Validation phase
    model.eval()
    val_loss, correct, total = 0.0, 0, 0
    all_preds, all_labels = [], []
    val_loader_progress = tqdm(val_loader, desc=f"Validation", leave=True)

    with torch.no_grad():
        for batch_idx, (inputs, labels) in enumerate(val_loader_progress):
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            val_loss += loss.item()
            _, preds = torch.max(outputs, 1)
            correct += (preds == labels).sum().item()
            total += labels.size(0)

            # Collect predictions and labels
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

            # Update progress bar with current batch accuracy
            val_loader_progress.set_postfix({"Batch Accuracy": (preds == labels).float().mean().item()})

    val_loader_progress.close()
    val_losses.append(val_loss / len(val_loader))
    val_accuracies.append(correct / total)
    scheduler.step()

    # Print summary for the epoch
    print(f"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_losses[-1]:.4f}, "
          f"Val Loss: {val_losses[-1]:.4f}, Val Accuracy: {val_accuracies[-1]:.4f}")

# Final results summary
print("\nTraining Completed!")
print("Final Training Loss:", train_losses[-1])
print("Final Validation Loss:", val_losses[-1])
print("Final Validation Accuracy:", val_accuracies[-1])

# Classification Report
print("\nClassification Report:")
print(classification_report(all_labels, all_preds, target_names=class_names))

# Confusion Matrix
cm = confusion_matrix(all_labels, all_preds)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=class_names, yticklabels=class_names)
plt.title(f"Confusion Matrix - Epoch {epoch+1}")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.show()

# Plot Training and Validation Loss
plt.figure(figsize=(10, 5))
plt.plot(train_losses, label="Training Loss")
plt.plot(val_losses, label="Validation Loss")
plt.title("Training and Validation Loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend()
plt.show()

"""# Improving the model"""

from collections import Counter
import torch

# Define the device (CPU or GPU)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Calculate class counts
class_counts = Counter([label for _, label in train_dataset])
total_samples = sum(class_counts.values())

# Compute class weights (inverse frequency)
class_weights = {class_id: total_samples / count for class_id, count in class_counts.items()}
class_weights_tensor = torch.tensor([class_weights[i] for i in range(len(class_counts))]).to(device)

print("Class Weights:", class_weights_tensor)

criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)

# Add Dropout to the fully connected layer
model.fc = nn.Sequential(
    nn.Dropout(0.5),  # Dropout layer to prevent overfitting
    nn.Linear(model.fc.in_features, num_classes)
)

!pip uninstall torch torchvision torchaudio
!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

import torch.optim as optim
from torch.optim.lr_scheduler import OneCycleLR

# Optimizer
optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)

# Scheduler
scheduler = OneCycleLR(
    optimizer,
    max_lr=0.01,  # Adjust based on your dataset and model size
    steps_per_epoch=len(train_loader),
    epochs=10,  # Number of epochs
    anneal_strategy="cos",  # Cosine annealing for smoother adjustment
    final_div_factor=10  # Final learning rate is max_lr / 10
)

# Training loop
train_losses, val_losses, val_accuracies = [], [], []
num_epochs = 10  # Number of epochs

class_names = ['bleached', 'healthy', 'partially']

for epoch in range(num_epochs):
    print(f"\nEpoch {epoch+1}/{num_epochs}")

    # Training loop
    model.train()
    running_loss = 0.0
    train_loader_progress = tqdm(train_loader, desc=f"Training", leave=True)

    for batch_idx, (inputs, labels) in enumerate(train_loader_progress):
        inputs, labels = inputs.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()

        # Update progress bar with current batch loss
        train_loader_progress.set_postfix({"Batch Loss": loss.item()})

    train_loader_progress.close()
    train_losses.append(running_loss / len(train_loader))

    # Validation phase
    model.eval()
    val_loss, correct, total = 0.0, 0, 0
    all_preds, all_labels = [], []
    val_loader_progress = tqdm(val_loader, desc=f"Validation", leave=True)

    with torch.no_grad():
        for batch_idx, (inputs, labels) in enumerate(val_loader_progress):
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            val_loss += loss.item()
            _, preds = torch.max(outputs, 1)
            correct += (preds == labels).sum().item()
            total += labels.size(0)

            # Collect predictions and labels
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

            # Update progress bar with current batch accuracy
            val_loader_progress.set_postfix({"Batch Accuracy": (preds == labels).float().mean().item()})

    val_loader_progress.close()
    val_losses.append(val_loss / len(val_loader))
    val_accuracies.append(correct / total)
    scheduler.step()

    # Print epoch summary
    print(f"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_losses[-1]:.4f}, "
          f"Val Loss: {val_losses[-1]:.4f}, Val Accuracy: {val_accuracies[-1]:.4f}")

# Final results summary
print("\nTraining Completed!")
print("Final Training Loss:", train_losses[-1])
print("Final Validation Loss:", val_losses[-1])
print("Final Validation Accuracy:", val_accuracies[-1])

# Classification Report
print("\nClassification Report:")
print(classification_report(all_labels, all_preds, target_names=class_names))

# Confusion Matrix
cm = confusion_matrix(all_labels, all_preds)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=class_names, yticklabels=class_names)
plt.title(f"Confusion Matrix - Epoch {epoch+1}")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.show()

# Plot Training and Validation Loss
plt.figure(figsize=(10, 5))
plt.plot(train_losses, label="Training Loss")
plt.plot(val_losses, label="Validation Loss")
plt.title("Training and Validation Loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend()
plt.show()

"""# Grad-CAM Implementation"""

!pip install grad-cam

# Get a single batch from the validation DataLoader
inputs, labels = next(iter(val_loader))  # Fetch a batch from validation set

# Select a single image from the batch
input_tensor = inputs[0].unsqueeze(0)  # Add batch dimension

# Move the tensor to the correct device
input_tensor = input_tensor.to(device)  # Move to GPU/CPU

from pytorch_grad_cam import GradCAM
from pytorch_grad_cam.utils.image import show_cam_on_image
import matplotlib.pyplot as plt

# Define the target layer
target_layer = model.layer4[-1]

# Initialize Grad-CAM
cam = GradCAM(model=model, target_layers=[target_layer])

# Get a single input tensor from the validation DataLoader
inputs, labels = next(iter(val_loader))  # Fetch a batch from validation set
input_tensor = inputs[0].unsqueeze(0).to(device)  # Select a single image and move to the correct device

# Generate the Grad-CAM heatmap
grayscale_cam = cam(input_tensor=input_tensor)[0]  # Generate Grad-CAM for the first image

# Convert the input tensor back to an image for visualization
input_image = input_tensor[0].permute(1, 2, 0).cpu().numpy()  # Convert to HWC format
input_image = (input_image - input_image.min()) / (input_image.max() - input_image.min())  # Normalize

# Overlay Grad-CAM heatmap on the input image
visualization = show_cam_on_image(input_image, grayscale_cam, use_rgb=True)

# Display the result
plt.imshow(visualization)
plt.axis('off')
plt.show()

model.eval()
misclassified = []

with torch.no_grad():
    for inputs, labels in val_loader:
        inputs, labels = inputs.to(device), labels.to(device)
        outputs = model(inputs)
        _, preds = torch.max(outputs, 1)

        # Collect misclassified examples
        for i in range(len(preds)):
            if preds[i] != labels[i]:  # Check for misclassification
                misclassified.append((inputs[i], labels[i], preds[i]))

print(f"Total misclassified examples: {len(misclassified)}")

from pytorch_grad_cam import GradCAM
from pytorch_grad_cam.utils.image import show_cam_on_image
import matplotlib.pyplot as plt

def visualize_gradcam(input_tensor, true_label, pred_label, model, target_layer, class_names):
    """
    Generate and visualize Grad-CAM heatmap for a given input.

    Args:
        input_tensor: Single input image tensor (1 x C x H x W).
        true_label: Ground truth label of the input image.
        pred_label: Predicted label of the input image.
        model: Trained PyTorch model.
        target_layer: Layer to target for Grad-CAM.
        class_names: List of class names.

    Returns:
        None
    """
    # Initialize Grad-CAM
    cam = GradCAM(model=model, target_layers=[target_layer])

    # Generate Grad-CAM heatmap
    grayscale_cam = cam(input_tensor=input_tensor)[0]

    # Convert tensor to image
    image = input_tensor[0].permute(1, 2, 0).cpu().numpy()  # Convert to HWC format
    image = (image - image.min()) / (image.max() - image.min())  # Normalize to [0, 1]

    # Overlay Grad-CAM on the image
    visualization = show_cam_on_image(image, grayscale_cam, use_rgb=True)

    # Display the result
    plt.figure(figsize=(6, 6))
    plt.imshow(visualization)
    plt.title(f"Grad-CAM Visualization\nTrue: {class_names[true_label]}, Predicted: {class_names[pred_label]}")
    plt.axis("off")
    plt.show()

target_layer = model.layer4[-1]  # Last convolutional block of ResNet50

# Visualize Grad-CAM for the first 5 misclassified examples
for img, true_label, pred_label in misclassified[:5]:
    input_tensor = img.unsqueeze(0).to(device)  # Add batch dimension and move to the correct device
    print(f"True Label: {class_names[true_label.item()]}, Predicted: {class_names[pred_label.item()]}")
    visualize_gradcam(input_tensor, true_label.item(), pred_label.item(), model, target_layer, class_names)

def display_gradcam_grid(misclassified, model, target_layer, class_names, num_images=6):
    """
    Display Grad-CAM visualizations for multiple misclassified examples in a grid.

    Args:
        misclassified: List of misclassified examples (image, true_label, pred_label).
        model: Trained PyTorch model.
        target_layer: Target layer for Grad-CAM.
        class_names: List of class names.
        num_images: Number of images to display in the grid.
    """
    # Limit the number of images to display
    num_images = min(num_images, len(misclassified))

    # Initialize Grad-CAM
    cam = GradCAM(model=model, target_layers=[target_layer])

    # Set up the grid for plotting
    cols = 3  # Number of columns in the grid
    rows = (num_images + cols - 1) // cols  # Calculate number of rows needed
    fig, axes = plt.subplots(rows, cols, figsize=(15, 5 * rows))
    axes = axes.flatten()  # Flatten to easily iterate over axes

    for i, (img, true_label, pred_label) in enumerate(misclassified[:num_images]):
        input_tensor = img.unsqueeze(0).to(device)  # Add batch dimension and move to the correct device

        # Generate Grad-CAM heatmap
        grayscale_cam = cam(input_tensor=input_tensor)[0]

        # Convert tensor to image
        image = input_tensor[0].permute(1, 2, 0).cpu().numpy()  # Convert to HWC format
        image = (image - image.min()) / (image.max() - image.min())  # Normalize to [0, 1]

        # Overlay Grad-CAM on the image
        visualization = show_cam_on_image(image, grayscale_cam, use_rgb=True)

        # Plot the result
        axes[i].imshow(visualization)
        axes[i].set_title(
            f"True: {class_names[true_label.item()]}\nPredicted: {class_names[pred_label.item()]}"
        )
        axes[i].axis("off")

    # Hide any unused subplots
    for j in range(num_images, len(axes)):
        axes[j].axis("off")

    plt.tight_layout()
    plt.show()

# Call the function to display a grid of misclassified examples
display_gradcam_grid(misclassified, model, target_layer, class_names, num_images=6)